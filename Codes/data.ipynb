{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7adc1994-a819-435b-bad0-e04a85900d69",
   "metadata": {},
   "source": [
    "## Calculating PM2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9657558e-8aac-4c6d-aeef-91e2e63c861d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Set the directory path\n",
    "metadata_dir = r'C:\\Users\\Akanksha\\OneDrive\\Desktop\\data\\Metadata'\n",
    "\n",
    "def load_and_standardize(filepath):\n",
    "    if filepath.endswith('.xlsx'):\n",
    "        df = pd.read_excel(filepath)\n",
    "    else:\n",
    "        df = pd.read_csv(filepath)\n",
    "    \n",
    "    # Rename inconsistent column names\n",
    "    rename_dict = {\n",
    "        \"Mass collected on filter\": \"Mass collected on filter (ug)\",\n",
    "        \"Sampled volume\": \"Sampled volume (m3)\"\n",
    "    }\n",
    "    df.rename(columns=rename_dict, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "combined_df = pd.concat(\n",
    "    [\n",
    "        load_and_standardize(os.path.join(metadata_dir, f))\n",
    "        for f in os.listdir(metadata_dir)\n",
    "        if f.endswith('.xlsx') or f.endswith('.csv')\n",
    "    ],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "# Remove rows with 'Filter Type' == 'FB'\n",
    "combined_df = combined_df[combined_df[\"Filter Type\"] != \"FB\"].copy()\n",
    "\n",
    "# Clean up column names: strip spaces and unify formatting\n",
    "combined_df.columns = combined_df.columns.str.strip()\n",
    "\n",
    "# Drop irrelevant columns\n",
    "columns_to_drop = [\"Shipment ID (Date)\", \"Shipment ID\", \"Cartridge Number\", \"Barcode\", \"Project ID\", \"Lot ID\", \"Comments\"]\n",
    "combined_df.drop(columns=columns_to_drop, inplace=True, errors='ignore')\n",
    "\n",
    "# Convert to numeric safely\n",
    "combined_df[\"Sampled volume (m3)\"] = pd.to_numeric(combined_df[\"Sampled volume (m3)\"], errors='coerce')\n",
    "combined_df[\"Mass collected on filter (ug)\"] = pd.to_numeric(combined_df[\"Mass collected on filter (ug)\"], errors='coerce')\n",
    "\n",
    "# Remove rows with zero or NaN volume before division\n",
    "combined_df = combined_df[\n",
    "    (combined_df[\"Sampled volume (m3)\"].notna()) &\n",
    "    (combined_df[\"Sampled volume (m3)\"] != 0)\n",
    "].copy()\n",
    "\n",
    "# Now safely calculate PM2.5\n",
    "combined_df[\"PM2.5(ug/m3)\"] = combined_df[\"Mass collected on filter (ug)\"] / combined_df[\"Sampled volume (m3)\"]\n",
    "\n",
    "# Filter only PM2.5 filters\n",
    "pm25_df = combined_df[combined_df[\"Filter Type\"] == \"PM2.5\"].copy()\n",
    "pm25_df.loc[pm25_df[\"PM2.5(ug/m3)\"] <= 0, \"PM2.5(ug/m3)\"] = np.nan\n",
    "pm25_df.dropna(subset=[\"PM2.5(ug/m3)\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75a92db7-4e09-4bdc-bc39-2064d08cecd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Filter ID', 'Analysis ID', 'Filter Type', 'Sampling Start Date',\n",
       "       'Sampling End Date', 'Mass collected on filter (ug)',\n",
       "       'Sampled volume (m3)', 'PM2.5(ug/m3)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm25_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "628a9173-2b10-40f7-9a80-2224ffc1d266",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm25_df[\"Filter ID\"] = pm25_df[\"Filter ID\"].str.replace(r'\\s*-\\s*', '-', regex=True).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0f21a9e-5a00-4ce7-92a0-1e5f270cdad4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filter ID</th>\n",
       "      <th>Analysis ID</th>\n",
       "      <th>Filter Type</th>\n",
       "      <th>Sampling Start Date</th>\n",
       "      <th>Sampling End Date</th>\n",
       "      <th>Mass collected on filter (ug)</th>\n",
       "      <th>Sampled volume (m3)</th>\n",
       "      <th>PM2.5(ug/m3)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USPA-0161-1</td>\n",
       "      <td>USPA-0161</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>10/14/2022</td>\n",
       "      <td>10/15/2022</td>\n",
       "      <td>56.7</td>\n",
       "      <td>7.344</td>\n",
       "      <td>7.720588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USPA-0162-2</td>\n",
       "      <td>USPA-0162</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>10/17/2022</td>\n",
       "      <td>10/18/2022</td>\n",
       "      <td>52.9</td>\n",
       "      <td>7.272</td>\n",
       "      <td>7.274477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USPA-0163-3</td>\n",
       "      <td>USPA-0163</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>10/20/2022</td>\n",
       "      <td>10/21/2022</td>\n",
       "      <td>36.0</td>\n",
       "      <td>7.272</td>\n",
       "      <td>4.950495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USPA-0164-4</td>\n",
       "      <td>USPA-0164</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>10/23/2022</td>\n",
       "      <td>10/24/2022</td>\n",
       "      <td>40.0</td>\n",
       "      <td>7.272</td>\n",
       "      <td>5.500550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USPA-0165-5</td>\n",
       "      <td>USPA-0165</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>10/26/2022</td>\n",
       "      <td>10/27/2022</td>\n",
       "      <td>44.2</td>\n",
       "      <td>7.272</td>\n",
       "      <td>6.078108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2781</th>\n",
       "      <td>PRFJ-0074-2</td>\n",
       "      <td>PRFJ-0074</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>2/5/2023</td>\n",
       "      <td>2/13/2023</td>\n",
       "      <td>27.3</td>\n",
       "      <td>7.200</td>\n",
       "      <td>3.791667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2782</th>\n",
       "      <td>PRFJ-0075-3</td>\n",
       "      <td>PRFJ-0075</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>2/14/2023</td>\n",
       "      <td>2/22/2023</td>\n",
       "      <td>30.7</td>\n",
       "      <td>7.200</td>\n",
       "      <td>4.263889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2783</th>\n",
       "      <td>PRFJ-0076-4</td>\n",
       "      <td>PRFJ-0076</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>2/23/2023</td>\n",
       "      <td>3/3/2023</td>\n",
       "      <td>39.1</td>\n",
       "      <td>7.200</td>\n",
       "      <td>5.430556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2784</th>\n",
       "      <td>PRFJ-0077-5</td>\n",
       "      <td>PRFJ-0077</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>3/4/2023</td>\n",
       "      <td>3/12/2023</td>\n",
       "      <td>36.0</td>\n",
       "      <td>6.798</td>\n",
       "      <td>5.295675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2785</th>\n",
       "      <td>AAAA-BLNK-X</td>\n",
       "      <td>AAAA-BLNK-X</td>\n",
       "      <td>NF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2786 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Filter ID  Analysis ID Filter Type Sampling Start Date  \\\n",
       "0     USPA-0161-1    USPA-0161       PM2.5          10/14/2022   \n",
       "1     USPA-0162-2    USPA-0162       PM2.5          10/17/2022   \n",
       "2     USPA-0163-3    USPA-0163       PM2.5          10/20/2022   \n",
       "3     USPA-0164-4    USPA-0164       PM2.5          10/23/2022   \n",
       "4     USPA-0165-5    USPA-0165       PM2.5          10/26/2022   \n",
       "...           ...          ...         ...                 ...   \n",
       "2781  PRFJ-0074-2    PRFJ-0074       PM2.5            2/5/2023   \n",
       "2782  PRFJ-0075-3    PRFJ-0075       PM2.5           2/14/2023   \n",
       "2783  PRFJ-0076-4    PRFJ-0076       PM2.5           2/23/2023   \n",
       "2784  PRFJ-0077-5    PRFJ-0077       PM2.5            3/4/2023   \n",
       "2785  AAAA-BLNK-X  AAAA-BLNK-X          NF                   0   \n",
       "\n",
       "     Sampling End Date  Mass collected on filter (ug)  Sampled volume (m3)  \\\n",
       "0           10/15/2022                           56.7                7.344   \n",
       "1           10/18/2022                           52.9                7.272   \n",
       "2           10/21/2022                           36.0                7.272   \n",
       "3           10/24/2022                           40.0                7.272   \n",
       "4           10/27/2022                           44.2                7.272   \n",
       "...                ...                            ...                  ...   \n",
       "2781         2/13/2023                           27.3                7.200   \n",
       "2782         2/22/2023                           30.7                7.200   \n",
       "2783          3/3/2023                           39.1                7.200   \n",
       "2784         3/12/2023                           36.0                6.798   \n",
       "2785                 0                            1.0                1.000   \n",
       "\n",
       "      PM2.5(ug/m3)  \n",
       "0         7.720588  \n",
       "1         7.274477  \n",
       "2         4.950495  \n",
       "3         5.500550  \n",
       "4         6.078108  \n",
       "...            ...  \n",
       "2781      3.791667  \n",
       "2782      4.263889  \n",
       "2783      5.430556  \n",
       "2784      5.295675  \n",
       "2785      1.000000  \n",
       "\n",
       "[2786 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add a blank average row to PM2.5 DataFrame\n",
    "blank_row = {\n",
    "    'Filter ID': 'AAAA-BLNK-X',\n",
    "    'Analysis ID': 'AAAA-BLNK-X',\n",
    "    'Filter Type': 'NF',\n",
    "    'Sampling Start Date': '0',\n",
    "    'Sampling End Date': '0',\n",
    "    'Mass collected on filter (ug)': 1,\n",
    "    'Sampled volume (m3)': 1,\n",
    "    'PM2.5(ug/m3)': 1\n",
    "}\n",
    "pm25_df = pd.concat([pm25_df, pd.DataFrame([blank_row])], ignore_index=True)\n",
    "\n",
    "# Display the PM2.5 DataFrame \n",
    "display(pm25_df)\n",
    "\n",
    "pm25_df.to_csv(\"pm25_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847eaa78-6ab0-4232-be00-9acc3be9fd0d",
   "metadata": {},
   "source": [
    "### Names of filters in reflectance folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdc13819-b53a-47db-8132-023cc6bbe63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "Reflectance_directory_path = r\"C:\\Users\\Akanksha\\OneDrive\\Desktop\\data\\ALL_Reflectance\"\n",
    "path = r\"C:\\Users\\Akanksha\\OneDrive\\Desktop\\data\"\n",
    "\n",
    "filter_ids = []\n",
    "\n",
    "for filename in os.listdir(Reflectance_directory_path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        filter_id = filename.split(\".\")[0]\n",
    "        filter_ids.append(filter_id)\n",
    "\n",
    "output_file = os.path.join(path, \"list_of_filter_ids_ref.txt\")\n",
    "with open(output_file, \"w\") as f:\n",
    "    for fid in filter_ids:\n",
    "        f.write(fid + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81223755-d0c5-4b1d-bfeb-6fb7f7fe9834",
   "metadata": {},
   "source": [
    "### Names of filters in transmittance folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07fac496-c7ad-492a-958f-6aa4caad831c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "Transmittance_directory_path = r\"C:\\Users\\Akanksha\\OneDrive\\Desktop\\data\\ALL_Transmittance\"\n",
    "path = r\"C:\\Users\\Akanksha\\OneDrive\\Desktop\\data\"\n",
    "\n",
    "filter_ids = []\n",
    "\n",
    "for filename in os.listdir(Transmittance_directory_path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        filter_id = filename.split(\".\")[0]\n",
    "        filter_ids.append(filter_id)\n",
    "\n",
    "output_file = os.path.join(path, \"list_of_filter_ids_tran.txt\")\n",
    "with open(output_file, \"w\") as f:\n",
    "    for fid in filter_ids:\n",
    "        f.write(fid + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53e3838-9316-4628-9351-7fdcb636406c",
   "metadata": {},
   "source": [
    "### Python Code to Compare the Two Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a496a18-bda7-489d-b95b-fd265e6ba68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only in file_tra (list_of_filter_ids_ref.txt): 5 items\n",
      "Only in file_ref (list_of_filter_ids_tran.txt): 4 items\n",
      "Common items: 2301\n"
     ]
    }
   ],
   "source": [
    "file1 = r\"C:\\Users\\Akanksha\\OneDrive\\Desktop\\data\\list_of_filter_ids_ref.txt\"\n",
    "file2 = r\"C:\\Users\\Akanksha\\OneDrive\\Desktop\\data\\list_of_filter_ids_tran.txt\"\n",
    "\n",
    "# Read and clean lines\n",
    "with open(file1, 'r') as f1, open(file2, 'r') as f2:\n",
    "    set1 = set(line.strip() for line in f1 if line.strip())\n",
    "    set2 = set(line.strip() for line in f2 if line.strip())\n",
    "\n",
    "# Differences\n",
    "only_in_file1 = sorted(set1 - set2)\n",
    "only_in_file2 = sorted(set2 - set1)\n",
    "common = sorted(set1 & set2)\n",
    "\n",
    "# Print summary\n",
    "print(f\"Only in file_tra ({os.path.basename(file1)}): {len(only_in_file1)} items\")\n",
    "print(f\"Only in file_ref ({os.path.basename(file2)}): {len(only_in_file2)} items\")\n",
    "print(f\"Common items: {len(common)}\")\n",
    "\n",
    "# Save results (optional)\n",
    "base_dir = os.path.dirname(file1)\n",
    "\n",
    "with open(os.path.join(base_dir, \"only_in_file_tra.txt\"), \"w\") as f:\n",
    "    f.writelines(line + \"\\n\" for line in only_in_file1)\n",
    "\n",
    "with open(os.path.join(base_dir, \"only_in_file_ref.txt\"), \"w\") as f:\n",
    "    f.writelines(line + \"\\n\" for line in only_in_file2)\n",
    "\n",
    "with open(os.path.join(base_dir, \"common_filters.txt\"), \"w\") as f:\n",
    "    f.writelines(line + \"\\n\" for line in common)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a72c54-5fcb-41fe-a0bf-1f773c105d79",
   "metadata": {},
   "source": [
    "### Moved files without PM2.5 data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3f987c3-5250-4b14-84f4-8b03cb15ba53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "source_dir = r\"C:\\Users\\Akanksha\\OneDrive\\Desktop\\data\\ALL_Reflectance\"  \n",
    "target_dir = os.path.join(source_dir, \"Files_without_PM25\")\n",
    "\n",
    "log_file_path = \"moved_files_ref.txt\"\n",
    "\n",
    "# Create target directory if it doesn't exist\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "# Get list of valid Filter IDs\n",
    "valid_filter_ids = set(pm25_df['Filter ID'].tolist())\n",
    "\n",
    "# Open log file for writing\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for filename in os.listdir(source_dir):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            base_name = filename.split(\".\")[0]\n",
    "            if base_name not in valid_filter_ids:\n",
    "                # Move file\n",
    "                src_path = os.path.join(source_dir, filename)\n",
    "                dst_path = os.path.join(target_dir, filename)\n",
    "                shutil.move(src_path, dst_path)\n",
    "                \n",
    "                # Log moved file\n",
    "                log_file.write(filename + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73dd3158-eea0-40d7-beaa-e22b676ba8b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "source_dir = r\"C:\\Users\\Akanksha\\OneDrive\\Desktop\\data\\ALL_Transmittance\"  \n",
    "target_dir = os.path.join(source_dir, \"Files_without_PM25\")\n",
    "\n",
    "log_file_path = \"moved_files_tran.txt\"\n",
    "\n",
    "# Create target directory if it doesn't exist\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "# Get list of valid Filter IDs\n",
    "valid_filter_ids = set(pm25_df['Filter ID'].tolist())\n",
    "\n",
    "# Open log file for writing\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for filename in os.listdir(source_dir):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            base_name = filename.split(\".\")[0]\n",
    "            if base_name not in valid_filter_ids:\n",
    "                # Move file\n",
    "                src_path = os.path.join(source_dir, filename)\n",
    "                dst_path = os.path.join(target_dir, filename)\n",
    "                shutil.move(src_path, dst_path)\n",
    "                \n",
    "                # Log moved file\n",
    "                log_file.write(filename + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca567f0-98d8-4692-841b-ef15eea86c4c",
   "metadata": {},
   "source": [
    "### common filters in ref and trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13f11966-9dea-4f58-9e76-c7a1a0ba2e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved common filter names to common.txt\n"
     ]
    }
   ],
   "source": [
    "# Paths to your two input .txt files\n",
    "file1_path = r\"C:\\Users\\Akanksha\\Documents\\Untitled Folder\\moved_files_ref.txt\"  \n",
    "file2_path = r\"C:\\Users\\Akanksha\\Documents\\Untitled Folder\\moved_files_tran.txt\"  \n",
    "\n",
    "# Function to extract filter IDs from file\n",
    "def extract_filter_ids(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return set(line.strip().split('.')[0] for line in file if line.strip())\n",
    "\n",
    "# Extract filter IDs from both files\n",
    "filters_1 = extract_filter_ids(file1_path)\n",
    "filters_2 = extract_filter_ids(file2_path)\n",
    "\n",
    "# Find common filters\n",
    "common_filters = filters_1.intersection(filters_2)\n",
    "\n",
    "# Save common filter names to common.txt\n",
    "with open(\"common.txt\", \"w\") as f:\n",
    "    for filter_id in sorted(common_filters):\n",
    "        f.write(filter_id + \"\\n\")\n",
    "\n",
    "print(\"Saved common filter names to common.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91544734-e306-41b8-a07f-42b6bb145095",
   "metadata": {},
   "source": [
    "### Cross check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a787f81f-c1b9-4995-b27e-3afb01c21032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No matches found between common.txt and pm25_df['Filter ID']\n"
     ]
    }
   ],
   "source": [
    "with open(\"common.txt\", \"r\") as f:\n",
    "    common_ids = set(line.strip() for line in f if line.strip())\n",
    "\n",
    "# Get Filter IDs from pm25_df as a set\n",
    "pm25_ids = set(pm25_df['Filter ID'].astype(str))\n",
    "\n",
    "# Find matching IDs\n",
    "matched_ids = common_ids.intersection(pm25_ids)\n",
    "\n",
    "# Report result\n",
    "if matched_ids:\n",
    "    print(\"Matches found:\")\n",
    "    for fid in sorted(matched_ids):\n",
    "        print(fid)\n",
    "else:\n",
    "    print(\"No matches found between common.txt and pm25_df['Filter ID']\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60349622-c59e-48b7-bd90-b94772739ebe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
